{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.getenv(\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = key\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7CjlcfS8IRd3AB95gQRT8e9X4Kvhz at 0x103a8e590> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"ChatGPT\\ub294 \\uc628\\ub77c\\uc778 \\uc0c1\\ub2f4 \\ubc0f \\uc9c8\\ubb38 \\ub2f5\\ubcc0\\uc744 \\uc704\\ud55c \\uc778\\uacf5\\uc9c0\\ub2a5 \\ucc57\\ubd07\\uc785\\ub2c8\\ub2e4. ChatGPT\\ub294 \\uc778\\uacf5\\uc9c0\\ub2a5 \\uae30\\uc220\\uc744 \\uae30\\ubc18\\uc73c\\ub85c, \\uc778\\uac04\\uacfc \\ub300\\ud654\\ud558\\ub294 \\uac83\\ucc98\\ub7fc \\ub300\\ud654\\ub97c \\uc9c4\\ud589\\ud558\\uc5ec \\uc0ac\\uc6a9\\uc790\\ub4e4\\uc5d0\\uac8c \\ub2e4\\uc591\\ud55c \\uc815\\ubcf4\\uc640 \\ub3c4\\uc6c0\\uc744 \\uc81c\\uacf5\\ud569\\ub2c8\\ub2e4.\\n\\nChatGPT\\ub294 \\uc5ec\\ub7ec \\ubd84\\uc57c\\uc5d0 \\ub300\\ud55c \\uc804\\ubb38\\uc801\\uc778 \\uc9c0\\uc2dd\\uc744 \\uac00\\uc9c0\\uace0 \\uc788\\uc73c\\uba70, \\uc0ac\\uc6a9\\uc790\\ub4e4\\uc774 \\uad81\\uae08\\ud574\\ud558\\ub294 \\ub2e4\\uc591\\ud55c \\uc8fc\\uc81c\\uc5d0 \\ub300\\ud55c \\ub2f5\\ubcc0\\uc744 \\uc81c\\uacf5\\ud569\\ub2c8\\ub2e4. \\uc608\\ub97c \\ub4e4\\uc5b4, \\uac74\\uac15, \\uad50\\uc721, \\uc5ec\\ud589, \\uc74c\\uc2dd \\ub4f1\\uc758 \\uc8fc\\uc81c\\uc5d0 \\ub300\\ud574\\uc11c\\ub3c4 \\ub3c4\\uc6c0\\uc744 \\uc90d\\ub2c8\\ub2e4.\\n\\n\\ub610\\ud55c, ChatGPT\\ub294 \\uc0ac\\uc6a9\\uc790\\ub4e4\\uc774 \\uc9c1\\uc811 \\uc9c8\\ubb38\\uc744 \\uc785\\ub825\\ud558\\uc5ec \\ub2f5\\ubcc0\\uc744 \\uc5bb\\uc744 \\uc218 \\uc788\\ub294 \\uae30\\ub2a5\\ub3c4 \\uc81c\\uacf5\\ud569\\ub2c8\\ub2e4. \\uc0ac\\uc6a9\\uc790\\ub4e4\\uc740 \\uc790\\uc2e0\\uc774 \\uad81\\uae08\\ud55c \\uc9c8\\ubb38\\uc744 \\uc785\\ub825\\ud558\\uba74, ChatGPT\\ub294 \\uadf8\\uc5d0 \\ub300\\ud55c \\ub2f5\\ubcc0\\uc744 \\uc989\\uc2dc \\uc81c\\uacf5\\ud569\\ub2c8\\ub2e4.\\n\\nChatGPT\\ub294 \\uc0ac\\uc6a9\\uc790\\ub4e4\\uc5d0\\uac8c \\ud3b8\\ub9ac\\ud55c \\uc11c\\ube44\\uc2a4\\ub97c \\uc81c\\uacf5\\ud558\\uc5ec, \\ub2e4\\uc591\\ud55c \\ubb38\\uc81c\\ub97c \\uc27d\\uac8c \\ud574\\uacb0\\ud560 \\uc218 \\uc788\\ub3c4\\ub85d \\uc9c0\\uc6d0\\ud558\\ub294 \\ud6a8\\uacfc\\uc801\\uc778 \\ub3c4\\uad6c\\uc785\\ub2c8\\ub2e4.\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683270220,\n",
       "  \"id\": \"chatcmpl-7CjlcfS8IRd3AB95gQRT8e9X4Kvhz\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 325,\n",
       "    \"prompt_tokens\": 31,\n",
       "    \"total_tokens\": 356\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "    {'role': 'user', 'content': 'ChatGPT에 대해 설명해줘.'},\n",
    "]\n",
    "\n",
    "res = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ChatGPT란 어떤 주제든지 대화를 나눌 수 있는 인공지능 챗봇입니다. ChatGPT는 실제로 발명된 인공지능 모델인 GPT-3 (Generative Pre-trained Transformer 3) 기반으로 작동합니다.\\n\\nChatGPT는 매우 자연스러운 대화를 제공하여 질문을 던지고 답변을 받을 수 있습니다. ChatGPT는 실시간 대화를 위해 최신 기술을 사용하여 만들어졌으며, 개인적인 관심사나 지식, 특정 토픽에 대한 정보, 문제 해결, 뉴스 등 다양한 분야에 대한 정보를 제공할 수 있습니다. 또한, ChatGPT는 대화의 너무 심화된 부분이 있을 때 인간 전문가로 연결 기능도 제공합니다.\\n\\nChatGPT는 새로운 기술 발견과 인공지능 지식의 향상에 중요한 역할을 하고 있으며, 향후 많은 분야에서 사용될 것으로 예상됩니다.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = res['choices'][0]['message']['content']\n",
    "\n",
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ChatGPT는 인공지능 챗봇이며, 다양한 분야에 대한 정보를 제공합니다. GPT-3를 기반으로 제작되었으며, 실시간 대화와 전문가와의 연결 기능을 제공합니다.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append({\n",
    "    'role': 'assistant',\n",
    "    'content': msg\n",
    "})\n",
    "\n",
    "messages.append({\n",
    "    'role': 'user',\n",
    "    'content': '위의 문장을 50자로 요약해줘.'\n",
    "})\n",
    "\n",
    "res = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "res['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "You are a helpful assistant for brainstorming ideas and topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=\"Brainstorm some ideas combining VR and fitness:\",\n",
    "  temperature=0.6,\n",
    "  max_tokens=150,\n",
    "  top_p=1,\n",
    "  frequency_penalty=1,\n",
    "  presence_penalty=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'message'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response[\u001b[39m'\u001b[39;49m\u001b[39mchoices\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mmessage\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'message'"
     ]
    }
   ],
   "source": [
    "response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Virtual reality fitness classes \n",
      "2. Immersive workout experiences in virtual worlds \n",
      "3. Interactive exercise games for the home gym \n",
      "4. Personalized fitness coaching with an AI-powered avatar \n",
      "5. Fitness challenges and competitions in a virtual world \n",
      "6. Wearable tracking devices that measure performance in VR exercises  \n",
      "7. Augmented reality workouts on a treadmill or stationary bike  \n",
      "8. Virtual obstacle courses to improve agility and coordination\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topics(data_list):\n",
    "    prompt = \"Generate 5 topics based on the following data:\\n\"\n",
    "    for data in data_list:\n",
    "        prompt += f\"- {data}\\n\"\n",
    "    prompt += \"1. \\n2. \\n3. \\n4. \\n5. \\n\"\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=500,\n",
    "        top_p=1,\n",
    "        frequency_penalty=1,\n",
    "        presence_penalty=1,\n",
    "        timeout=10,\n",
    "        n=1,\n",
    "        stop=None\n",
    "        )\n",
    "    topics = re.findall(r\"\\d+\\.\\s(.+)\", response.choices[0].text)\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = ['서울글로벌센터 구인광고','서울글로벌센터 월별 접수유형별 분류별 상담실적','서울글로벌센터 월별 상담실적']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['서울글로벌센터 구인광고 분석',\n",
       " '월별 상담실 접수 분류',\n",
       " '상담실 접수 빈도 분야별 분산',\n",
       " '월볆의 특화한 구인 광고 통합',\n",
       " '상담의 효과: 업무/품은/학業/etc']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topics(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Generate 5 topics based on the following data:\\n\"\n",
    "for data in datas:\n",
    "    prompt += f\"- {data}\\n\"\n",
    "prompt += \"1. \\n2. \\n3. \\n4. \\n5. \\n\"\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    temperature=0.5,\n",
    "    max_tokens=500,\n",
    "    top_p=1,\n",
    "    frequency_penalty=1,\n",
    "    presence_penalty=1,\n",
    "    timeout=10,\n",
    "    n=1,\n",
    "    stop=None\n",
    "    )\n",
    "topics = re.findall(r\"\\d+\\.\\s(.+)\", response.choices[0].text)[:num_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_text(data_dict:dict, field:str, purpose:str, num_topics:int) -> str:\n",
    "    prompt = f\"Generate {num_topics} topics in the {field} field for the following purpose: {purpose}\\n\\nData:\\n\"\n",
    "    for key, value in data_dict.items():\n",
    "        prompt += f\"- {key} ({len(value[1])} columns): {value[0]}\\n\\tColumns: {', '.join(value[1])}\\n\"\n",
    "    prompt += f\"\\n1. \\n2. \\n3. \\n4. \\n5. \\n\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\"name_1\":[\"text_1\",['col_11','col_12']],\n",
    "                \"name_2\":[\"text_2\",['col_21','col_22']],\n",
    "                \"name_3\":[\"text_3\",['col_41','col_42']]}\n",
    "field = 'ss'\n",
    "purpose = 'hi'\n",
    "num_topics = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate 5 topics in the ss field for the following purpose: hi\n",
      "\n",
      "Data:\n",
      "- name_1 (2 columns): text_1\n",
      "\tColumns: col_11, col_12\n",
      "- name_2 (2 columns): text_2\n",
      "\tColumns: col_21, col_22\n",
      "- name_3 (2 columns): text_3\n",
      "\tColumns: col_41, col_42\n",
      "\n",
      "1. \n",
      "2. \n",
      "3. \n",
      "4. \n",
      "5. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = prompt_text(data_dict, field, purpose, num_topics)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=res,\n",
    "    temperature=0.5,\n",
    "    max_tokens=500,\n",
    "    top_p=1,\n",
    "    frequency_penalty=1,\n",
    "    presence_penalty=1,\n",
    "    timeout=10,\n",
    "    n=1,\n",
    "    stop=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Text Analysis of name_1: col_11 and col_12\n",
      "2. Text Analysis of name_2: col_21 and col_22\n",
      "3. Text Mining Techniques for name_3: col 41 and col 42\n",
      "4. Natural Language Processing for text 1, 2, 3 \n",
      "5. Sentiment Analysis of all three texts\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = re.findall(r\"\\d+\\.\\s(.+)\", response.choices[0].text)[:num_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tiktoken"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[링크](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)\n",
    "\n",
    "\n",
    "|Encoding name|OpenAI models|\n",
    "------\n",
    "- cl100k_base : gpt-4, gpt-3.5-turbo, text-embedding-ada-002|\n",
    "- p50k_base : Codex models, text-davinci-002, text-davinci-003|\n",
    "- r50k_base (or gpt2) : GPT-3 models like davinci|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(res, 'p50k_base')\n",
    "# num_tokens_from_string(res, 'cl100k_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(res, 'cl100k_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seoul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
